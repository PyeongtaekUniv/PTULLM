{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d85a29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q langchain openai tiktoken chromadb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "dffa7287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ded9814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "83dc0d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loader = TextLoader('single_text_file.txt')\n",
    "loader = DirectoryLoader('../data2/', glob=\"*.txt\", loader_cls=TextLoader)\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e9e707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7863"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=250)\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e38ed7ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='학생이 교직 설치학과의 교직승인 인원을 초과할 경우에는 해당연도 1학년 1, 2학기 성적을 고려하여(실점수백분율환산점) 성적순으로 최종 선발한다. 제5조 (이수기간) 교직과정은 2학년 1학기부터 최종 학년까지 단계적으로 이수함을 원칙으로 한다. 제6조 (교과목 및 이수학점) ① 교직과정 이수자는 교직과목 22학점 이상(별표 2)과 전공과목 50학점[특수학교 80학점(기본이수영역포함)]이상을 취득하여야 한다.(개정 2009.06.12.) ② 교직과정 이수학생은 기본이수영역의 표시과목에 해당하는 과목(7과목, 21학점이상)을 이수하여야 한다.(별표3)(개정2009.06.12.) ③ 기본이수과목이라 함은 교직을 이수하려 할 때 전공자로서 반드시 이수하여야하는 과목을 말한다. ④ 교직과정을 이수한 자에 대한 교원자격증 신청기준은 전공 평균점수 75/100점 이상, 교직 평균점수 80/100점 이상인 자를 합격으로 한다.(개정 2009.06.12., 2013.05.21.) ⑤ 교직과정', metadata={'source': '../data2/교직과정 운영규정(190624).txt'}),\n",
       " Document(page_content='교직과정 이수학생은 기본이수영역의 표시과목에 해당하는 과목(7과목, 21학점이상)을 이수하여야 한다.(별표3)(개정2009.06.12.) ③ 기본이수과목이라 함은 교직을 이수하려 할 때 전공자로서 반드시 이수하여야하는 과목을 말한다. ④ 교직과정을 이수한 자에 대한 교원자격증 신청기준은 전공 평균점수 75/100점 이상, 교직 평균점수 80/100점 이상인 자를 합격으로 한다.(개정 2009.06.12., 2013.05.21.) ⑤ 교직과정 이수자는 반드시 교직과정 이수신청서에 희망한 주전공과 최종 졸업 시 주전공이 동일하여야 한다. ⑥ 교직과정 이수자는 교직과정 학과에서 명시한 교과교육영역의 3과목 이상을 이수해야 한다. 교과교육영역의 교수요목은 [별표4]와 같다.(신설 2013.05.13.) ⑦ 교직과정 이수자는“교직적성 및 인성검사” 합격 판정을 2회 이상 받아야 한다.(신설 2013.05.13.) ⑧ 평균점수의 산출방법은 [별표5]와 같다.(신설 2013.05.13.) ⑨', metadata={'source': '../data2/교직과정 운영규정(190624).txt'})]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[2:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "228dbeb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dfc53296",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5db183c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 682548 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 571884 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 847028 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 740247 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 645381 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 532996 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 727664 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 621193 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 815881 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 710844 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 606289 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 8.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 515031 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 661250 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 542170 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 731707 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n",
      "Retrying langchain.embeddings.openai.embed_with_retry.<locals>._embed_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for text-embedding-ada-002 in organization org-HbjvgAamK7qib49wXdOzo0QC on tokens per min. Limit: 1000000 / min. Current: 637332 / min. Visit https://platform.openai.com/account/rate-limits to learn more..\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=texts, \n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47516562",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f70d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory, \n",
    "    embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056968a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec359ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
